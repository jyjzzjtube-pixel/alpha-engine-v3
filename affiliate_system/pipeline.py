# -*- coding: utf-8 -*-
"""
1ì£¼ì œ â†’ 3í”Œë«í¼ í’€ íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
=============================================
ì¿ íŒ¡ ìƒí’ˆ URL ë˜ëŠ” ì£¼ì œ í…ìŠ¤íŠ¸ í•˜ë‚˜ë¥¼ ì…ë ¥í•˜ë©´:
  1. ìƒí’ˆ ìŠ¤í¬ë˜í•‘ (ì¿ íŒ¡) or ì£¼ì œ ê¸°ë°˜ Product ìƒì„±
  2. AI ì½˜í…ì¸  ìƒì„± (YouTube Shorts / Instagram Reels / Naver Blog)
  3. ìŠ¤í†¡ ì´ë¯¸ì§€ ìˆ˜ì§‘ (Pexels + Unsplash)
  4. ì¸ë„¤ì¼ ìë™ ìƒì„± (3í”Œë«í¼)
  5. ì˜ìƒ ë Œë”ë§ (3í”Œë«í¼)
  6. (ì„ íƒ) ìë™ ì—…ë¡œë“œ/ë°œí–‰

ëª¨ë“  ê¸°ì¡´ ëª¨ë“ˆì„ ì¬ì‚¬ìš©í•˜ë©° ìƒˆë¡œìš´ ì½”ë“œëŠ” ì—°ê²° ë¡œì§ë§Œ ë‹´ë‹¹í•œë‹¤.
"""
from __future__ import annotations

import argparse
import sys
import time
import uuid
from datetime import datetime
from pathlib import Path
from typing import Optional

from affiliate_system.config import RENDER_OUTPUT_DIR, WORK_DIR
from affiliate_system.models import (
    Product, AIContent, Campaign, Platform,
    RenderConfig, PLATFORM_PRESETS,
    CampaignStatus,
)
from affiliate_system.utils import setup_logger, ensure_dir

__all__ = ["ContentPipeline"]

logger = setup_logger("pipeline", "pipeline.log")

# ì§€ì› í”Œë«í¼ ì „ì²´
ALL_PLATFORMS = [Platform.YOUTUBE, Platform.INSTAGRAM, Platform.NAVER_BLOG]


class ContentPipeline:
    """1ì£¼ì œ â†’ 3í”Œë«í¼ í’€ ìë™í™” íŒŒì´í”„ë¼ì¸.

    ì‚¬ìš©ë²•:
        pipeline = ContentPipeline()
        results = pipeline.run("https://www.coupang.com/vp/products/123456")
        # ë˜ëŠ”
        results = pipeline.run("ì˜¤ë ˆë…¸ì¹´ì¸  í”„ë¦¬ë¯¸ì—„ ëˆì¹´ì¸ ", brand="ì˜¤ë ˆë…¸ì¹´ì¸ ")
    """

    def __init__(self):
        self._output_dir = ensure_dir(RENDER_OUTPUT_DIR)
        self._media_dir = ensure_dir(WORK_DIR / "media_downloads")
        logger.info("ContentPipeline ì´ˆê¸°í™” ì™„ë£Œ")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë©”ì¸ íŒŒì´í”„ë¼ì¸
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def run(
        self,
        topic_or_url: str,
        platforms: Optional[list[Platform]] = None,
        brand: str = "",
        persona: str = "",
        auto_upload: bool = False,
    ) -> dict:
        """í’€ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•œë‹¤.

        Args:
            topic_or_url: ì¿ íŒ¡ ìƒí’ˆ URL ë˜ëŠ” ì£¼ì œ í…ìŠ¤íŠ¸
            platforms: ëŒ€ìƒ í”Œë«í¼ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ 3ê°œ ëª¨ë‘)
            brand: ë¸Œëœë“œëª… (ë¸Œëœë”© ì ìš© ì‹œ)
            persona: AI í˜ë¥´ì†Œë‚˜
            auto_upload: Trueì´ë©´ ìë™ ì—…ë¡œë“œê¹Œì§€ ìˆ˜í–‰

        Returns:
            {
              "campaign": Campaign ê°ì²´,
              "platforms": {
                "youtube": {"video": path, "thumbnail": path, "content": dict},
                "instagram": {...},
                "naver_blog": {...},
              },
              "upload_results": {...} (auto_uploadì¼ ë•Œë§Œ)
            }
        """
        platforms = platforms or ALL_PLATFORMS
        campaign_id = uuid.uuid4().hex[:8]
        start_time = time.time()

        logger.info(f"{'='*60}")
        logger.info(f"íŒŒì´í”„ë¼ì¸ ì‹œì‘: {topic_or_url[:60]}")
        logger.info(f"ìº í˜ì¸ ID: {campaign_id}")
        logger.info(f"í”Œë«í¼: {[p.value for p in platforms]}")
        logger.info(f"{'='*60}")

        results: dict = {"platforms": {}, "upload_results": {}}

        # â”€â”€ Step 1: ìƒí’ˆ ì •ë³´ ì¤€ë¹„ â”€â”€
        print(f"\n[1/6] ìƒí’ˆ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
        product = self._prepare_product(topic_or_url)
        logger.info(f"ìƒí’ˆ ì¤€ë¹„ ì™„ë£Œ: {product.title}")
        print(f"  âœ“ ìƒí’ˆ: {product.title}")
        print(f"  âœ“ ê°€ê²©: {product.price or '(ë¯¸ì§€ì •)'}")
        print(f"  âœ“ ì œíœ´ë§í¬: {product.affiliate_link or '(ì—†ìŒ)'}")

        # â”€â”€ Step 2: AI ì½˜í…ì¸  ìƒì„± â”€â”€
        print(f"\n[2/6] AI ì½˜í…ì¸  ìƒì„± ì¤‘ ({len(platforms)}ê°œ í”Œë«í¼)...")
        platform_contents = self._generate_contents(product, platforms, persona, brand)
        for p_name, content in platform_contents.items():
            narr_count = len(content.get("narration", []))
            hash_count = len(content.get("hashtags", []))
            print(f"  âœ“ {p_name}: ì œëª©={len(content.get('title',''))}ì, "
                  f"ë‚˜ë ˆì´ì…˜={narr_count}ì¥ë©´, í•´ì‹œíƒœê·¸={hash_count}ê°œ")

        # â”€â”€ Step 3: ë¯¸ë””ì–´ ìˆ˜ì§‘ â”€â”€
        print(f"\n[3/6] ìŠ¤í†¡ ì´ë¯¸ì§€ ìˆ˜ì§‘ ì¤‘...")
        images = self._collect_media(product)
        print(f"  âœ“ ì´ë¯¸ì§€ {len(images)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")

        # â”€â”€ Step 4: ì¸ë„¤ì¼ ìƒì„± â”€â”€
        print(f"\n[4/6] ì¸ë„¤ì¼ ìƒì„± ì¤‘...")
        thumbnails = self._generate_thumbnails(
            platforms, platform_contents, images, brand, campaign_id,
        )
        for p_name, thumb_path in thumbnails.items():
            print(f"  âœ“ {p_name}: {Path(thumb_path).name}")

        # â”€â”€ Step 5: ì˜ìƒ ë Œë”ë§ â”€â”€
        print(f"\n[5/6] ì˜ìƒ ë Œë”ë§ ì¤‘...")
        videos = self._render_videos(
            platforms, platform_contents, images, brand, campaign_id,
        )
        for p_name, video_path in videos.items():
            if video_path:
                size_mb = Path(video_path).stat().st_size / (1024 * 1024)
                print(f"  âœ“ {p_name}: {Path(video_path).name} ({size_mb:.1f}MB)")
            else:
                print(f"  âœ— {p_name}: ë Œë”ë§ ì‹¤íŒ¨")

        # ê²°ê³¼ ì¡°í•©
        campaign = Campaign(
            id=campaign_id,
            product=product,
            ai_content=AIContent(
                platform_contents=platform_contents,
            ),
            status=CampaignStatus.COMPLETE,
            target_platforms=platforms,
            platform_videos=videos,
            platform_thumbnails=thumbnails,
            created_at=datetime.now(),
        )

        for p in platforms:
            p_name = p.value
            results["platforms"][p_name] = {
                "video": videos.get(p_name, ""),
                "thumbnail": thumbnails.get(p_name, ""),
                "content": platform_contents.get(p_name, {}),
            }

        results["campaign"] = campaign

        # â”€â”€ Step 6: ìë™ ì—…ë¡œë“œ â”€â”€
        if auto_upload:
            print(f"\n[6/6] ìë™ ì—…ë¡œë“œ ì¤‘...")
            upload_results = self._upload_all(campaign)
            results["upload_results"] = upload_results
            for p_name, result in upload_results.items():
                status = "âœ“ ì„±ê³µ" if result.get("ok") else "âœ— ì‹¤íŒ¨"
                print(f"  {status}: {p_name}")
        else:
            print(f"\n[6/6] ì—…ë¡œë“œ ê±´ë„ˆëœ€ (--upload í”Œë˜ê·¸ë¡œ í™œì„±í™”)")

        elapsed = time.time() - start_time
        print(f"\n{'='*60}")
        print(f"íŒŒì´í”„ë¼ì¸ ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {elapsed:.1f}ì´ˆ)")
        print(f"ì¶œë ¥ ê²½ë¡œ: {self._output_dir}")
        print(f"{'='*60}\n")

        logger.info(f"íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {elapsed:.1f}ì´ˆ")
        return results

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 1: ìƒí’ˆ ì •ë³´ ì¤€ë¹„
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _prepare_product(self, topic_or_url: str) -> Product:
        """ì…ë ¥ì´ URLì´ë©´ ìŠ¤í¬ë˜í•‘, í…ìŠ¤íŠ¸ì´ë©´ ì£¼ì œ ê¸°ë°˜ Product ìƒì„±."""
        from affiliate_system.coupang_scraper import CoupangScraper

        if CoupangScraper.is_coupang_url(topic_or_url):
            logger.info("ì¿ íŒ¡ URL ê°ì§€ â€” ìŠ¤í¬ë˜í•‘ ì‹œì‘")
            scraper = CoupangScraper()
            return scraper.scrape_and_link(topic_or_url)

        # URLì´ì§€ë§Œ ì¿ íŒ¡ì´ ì•„ë‹Œ ê²½ìš° (ì¼ë°˜ URL)
        if topic_or_url.startswith("http"):
            logger.info("ì¼ë°˜ URL ê°ì§€ â€” OG íƒœê·¸ ìŠ¤í¬ë˜í•‘")
            return self._scrape_generic_url(topic_or_url)

        # í…ìŠ¤íŠ¸ ì£¼ì œ â€” Product ê°ì²´ë¡œ ë³€í™˜
        logger.info(f"ì£¼ì œ í…ìŠ¤íŠ¸ ì…ë ¥: {topic_or_url}")
        return Product(
            title=topic_or_url,
            description=topic_or_url,
            scraped_at=datetime.now(),
        )

    def _scrape_generic_url(self, url: str) -> Product:
        """ì¼ë°˜ URLì—ì„œ OG íƒœê·¸ë¡œ ê¸°ë³¸ ìƒí’ˆ ì •ë³´ë¥¼ ì¶”ì¶œí•œë‹¤."""
        import requests
        from bs4 import BeautifulSoup

        try:
            headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
            resp = requests.get(url, headers=headers, timeout=15)
            resp.raise_for_status()
            soup = BeautifulSoup(resp.text, "html.parser")

            title = ""
            description = ""
            image_urls = []

            og_title = soup.find("meta", property="og:title")
            if og_title:
                title = og_title.get("content", "")

            og_desc = soup.find("meta", property="og:description")
            if og_desc:
                description = og_desc.get("content", "")

            og_image = soup.find("meta", property="og:image")
            if og_image and og_image.get("content"):
                image_urls.append(og_image["content"])

            if not title:
                t = soup.find("title")
                title = t.get_text(strip=True) if t else url

            return Product(
                url=url,
                title=title,
                description=description,
                image_urls=image_urls,
                scraped_at=datetime.now(),
            )
        except Exception as e:
            logger.warning(f"ì¼ë°˜ URL ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
            return Product(url=url, title=url, scraped_at=datetime.now())

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 2: AI ì½˜í…ì¸  ìƒì„±
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _generate_contents(
        self, product: Product, platforms: list[Platform],
        persona: str = "", brand: str = "",
    ) -> dict[str, dict]:
        """í”Œë«í¼ë³„ AI ì½˜í…ì¸ ë¥¼ ìƒì„±í•œë‹¤."""
        from affiliate_system.ai_generator import AIGenerator

        gen = AIGenerator()
        results: dict[str, dict] = {}

        for platform in platforms:
            try:
                logger.info(f"AI ì½˜í…ì¸  ìƒì„±: {platform.value}")
                content = gen.generate_platform_content(
                    product, platform, persona=persona, brand=brand,
                )
                results[platform.value] = content
            except Exception as e:
                logger.error(f"AI ìƒì„± ì‹¤íŒ¨ ({platform.value}): {e}")
                results[platform.value] = {
                    "title": product.title,
                    "body": "",
                    "hashtags": [],
                    "narration": [],
                    "cta": "",
                    "thumbnail_text": product.title[:7],
                    "thumbnail_subtitle": "",
                }

        cost = gen.get_session_cost()
        logger.info(f"AI ìƒì„± ë¹„ìš©: ${cost:.6f}")
        return results

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 3: ë¯¸ë””ì–´ ìˆ˜ì§‘
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _collect_media(self, product: Product) -> list[str]:
        """ìŠ¤í†¡ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì§‘í•˜ê³  ë‹¤ìš´ë¡œë“œí•œë‹¤."""
        from affiliate_system.media_collector import MediaCollector

        collector = MediaCollector()
        downloaded: list[str] = []

        # ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„± (ìƒí’ˆëª…ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ)
        query = product.title[:30] if product.title else "product"
        # í•œêµ­ì–´ í‚¤ì›Œë“œëŠ” ì˜ì–´ë¡œ ë³€í™˜í•˜ì—¬ ê²€ìƒ‰
        query_en = self._extract_search_keywords(product)

        # Pexels + Unsplash í†µí•© ê²€ìƒ‰
        all_results: list[dict] = []
        try:
            pexels = collector.search_pexels_images(query_en, count=5)
            all_results.extend(pexels)
        except Exception as e:
            logger.warning(f"Pexels ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

        try:
            unsplash = collector.search_unsplash_images(query_en, count=5)
            all_results.extend(unsplash)
        except Exception as e:
            logger.warning(f"Unsplash ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

        # ìƒìœ„ 5ê°œ ë‹¤ìš´ë¡œë“œ
        for item in all_results[:5]:
            try:
                img_url = item.get("url", "")
                if img_url:
                    path = collector.download_image(img_url)
                    if path:
                        downloaded.append(path)
            except Exception as e:
                logger.warning(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")

        # ìƒí’ˆ ìì²´ ì´ë¯¸ì§€ë„ ë‹¤ìš´ë¡œë“œ
        for img_url in product.image_urls[:3]:
            try:
                path = collector.download_image(img_url)
                if path:
                    downloaded.append(path)
            except Exception:
                pass

        logger.info(f"ë¯¸ë””ì–´ ìˆ˜ì§‘ ì™„ë£Œ: {len(downloaded)}ê°œ")
        return downloaded

    def _extract_search_keywords(self, product: Product) -> str:
        """ìƒí’ˆ ì •ë³´ì—ì„œ ì˜ì–´ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•œë‹¤."""
        title = product.title or ""
        # ê°„ë‹¨í•œ í•œâ†’ì˜ í‚¤ì›Œë“œ ë§¤í•‘ (ìì£¼ ì“°ì´ëŠ” ìŒì‹/ìƒí’ˆ ì¹´í…Œê³ ë¦¬)
        keyword_map = {
            "ëˆì¹´ì¸ ": "tonkatsu pork cutlet",
            "ì¹´ì¸ ": "katsu cutlet",
            "ì§¬ë½•": "jjamppong spicy noodle",
            "í”„ëœì°¨ì´ì¦ˆ": "franchise business",
            "ì°½ì—…": "startup business",
            "í™”ì¥í’ˆ": "cosmetics beauty",
            "ì˜ë¥˜": "fashion clothing",
            "ì „ìì œí’ˆ": "electronics gadget",
            "ì‹í’ˆ": "food gourmet",
            "ê±´ê°•": "health wellness",
            "ë‹¤ì´ì–´íŠ¸": "diet fitness",
            "ì£¼ë°©": "kitchen cooking",
            "ì¸í…Œë¦¬ì–´": "interior home decor",
            "ìº í•‘": "camping outdoor",
        }

        for kr, en in keyword_map.items():
            if kr in title:
                return en

        # ê¸°ë³¸: ìƒí’ˆ ì¹´í…Œê³ ë¦¬ ì¶”ì •
        return "product review lifestyle"

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 4: ì¸ë„¤ì¼ ìƒì„±
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _generate_thumbnails(
        self,
        platforms: list[Platform],
        contents: dict[str, dict],
        images: list[str],
        brand: str,
        campaign_id: str,
    ) -> dict[str, str]:
        """í”Œë«í¼ë³„ ì¸ë„¤ì¼ì„ ìƒì„±í•œë‹¤."""
        from affiliate_system.thumbnail_generator import ThumbnailGenerator

        gen = ThumbnailGenerator()
        thumbnails: dict[str, str] = {}

        bg_image = images[0] if images else ""

        for platform in platforms:
            p_name = platform.value
            content = contents.get(p_name, {})
            title = content.get("thumbnail_text", "") or content.get("title", "")[:7]
            subtitle = content.get("thumbnail_subtitle", "")

            output_path = str(
                self._output_dir / f"{campaign_id}_{p_name}_thumb.jpg"
            )

            try:
                result = gen.generate(
                    platform=platform,
                    title=title,
                    subtitle=subtitle,
                    background_image=bg_image,
                    brand=brand,
                    output_path=output_path,
                )
                thumbnails[p_name] = result
                logger.info(f"ì¸ë„¤ì¼ ìƒì„± ì™„ë£Œ: {p_name}")
            except Exception as e:
                logger.error(f"ì¸ë„¤ì¼ ìƒì„± ì‹¤íŒ¨ ({p_name}): {e}")
                thumbnails[p_name] = ""

        return thumbnails

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 5: ì˜ìƒ ë Œë”ë§
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _render_videos(
        self,
        platforms: list[Platform],
        contents: dict[str, dict],
        images: list[str],
        brand: str,
        campaign_id: str,
    ) -> dict[str, str]:
        """í”Œë«í¼ë³„ ì˜ìƒì„ ë Œë”ë§í•œë‹¤."""
        from affiliate_system.video_editor import VideoForge

        videos: dict[str, str] = {}

        if not images:
            logger.warning("ì´ë¯¸ì§€ ì—†ìŒ â€” ì˜ìƒ ë Œë”ë§ ê±´ë„ˆëœ€")
            return {p.value: "" for p in platforms}

        for platform in platforms:
            p_name = platform.value
            content = contents.get(p_name, {})
            narrations = content.get("narration", [])
            cta = content.get("cta", "")
            body = content.get("body", "")

            output_path = str(
                self._output_dir / f"{campaign_id}_{p_name}_video.mp4"
            )

            try:
                # í”Œë«í¼ í”„ë¦¬ì…‹ìœ¼ë¡œ RenderConfig ìƒì„±
                preset = PLATFORM_PRESETS[platform]
                config = RenderConfig.from_platform_preset(preset, brand=brand)
                forge = VideoForge(config=config)

                result = forge.render_for_platform(
                    platform=platform,
                    images=images[:5],  # ìµœëŒ€ 5ê°œ ì´ë¯¸ì§€
                    narrations=narrations,
                    output_path=output_path,
                    subtitle_text=body[:200],
                    brand=brand,
                    cta_text=cta,
                )
                videos[p_name] = result
                logger.info(f"ì˜ìƒ ë Œë”ë§ ì™„ë£Œ: {p_name}")
            except Exception as e:
                logger.error(f"ì˜ìƒ ë Œë”ë§ ì‹¤íŒ¨ ({p_name}): {e}")
                videos[p_name] = ""

        return videos

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 6: ìë™ ì—…ë¡œë“œ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _upload_all(self, campaign: Campaign) -> dict:
        """ëª¨ë“  í”Œë«í¼ì— ì—…ë¡œë“œí•œë‹¤."""
        from affiliate_system.auto_uploader import StealthUploader

        uploader = StealthUploader()
        results = uploader.upload_campaign(campaign)
        return results


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI ì§„ì…ì 
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    parser = argparse.ArgumentParser(
        description="1ì£¼ì œ â†’ 3í”Œë«í¼ ì½˜í…ì¸  ìë™ ìƒì„± íŒŒì´í”„ë¼ì¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  %(prog)s "https://www.coupang.com/vp/products/123456"
  %(prog)s "ì˜¤ë ˆë…¸ì¹´ì¸  í”„ë¦¬ë¯¸ì—„ ëˆì¹´ì¸ " --brand ì˜¤ë ˆë…¸ì¹´ì¸ 
  %(prog)s "ë‹¤ì´ì–´íŠ¸ ë³´ì¶©ì œ" --platforms youtube instagram
  %(prog)s "https://www.coupang.com/vp/products/123" --upload
        """,
    )
    parser.add_argument("topic", help="ì¿ íŒ¡ ìƒí’ˆ URL ë˜ëŠ” ì£¼ì œ í…ìŠ¤íŠ¸")
    parser.add_argument("--brand", default="", help="ë¸Œëœë“œëª… (ì˜¤ë ˆë…¸ì¹´ì¸ /ë¬´ì‚¬ì§¬ë½•/ë¸Œë¦¿ì§€ì›)")
    parser.add_argument("--persona", default="", help="AI í˜ë¥´ì†Œë‚˜")
    parser.add_argument(
        "--platforms", nargs="+",
        choices=["youtube", "instagram", "naver_blog"],
        default=None,
        help="ëŒ€ìƒ í”Œë«í¼ (ê¸°ë³¸: 3ê°œ ëª¨ë‘)",
    )
    parser.add_argument("--upload", action="store_true", help="ìë™ ì—…ë¡œë“œ í™œì„±í™”")

    args = parser.parse_args()

    # í”Œë«í¼ íŒŒì‹±
    platforms = None
    if args.platforms:
        platform_map = {
            "youtube": Platform.YOUTUBE,
            "instagram": Platform.INSTAGRAM,
            "naver_blog": Platform.NAVER_BLOG,
        }
        platforms = [platform_map[p] for p in args.platforms]

    pipeline = ContentPipeline()
    results = pipeline.run(
        topic_or_url=args.topic,
        platforms=platforms,
        brand=args.brand,
        persona=args.persona,
        auto_upload=args.upload,
    )

    # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    print("\nğŸ“Š ê²°ê³¼ ìš”ì•½:")
    for p_name, data in results["platforms"].items():
        video = "âœ“" if data.get("video") else "âœ—"
        thumb = "âœ“" if data.get("thumbnail") else "âœ—"
        content = data.get("content", {})
        title_len = len(content.get("title", ""))
        print(f"  {p_name}: ì˜ìƒ{video} ì¸ë„¤ì¼{thumb} ì œëª©{title_len}ì")


if __name__ == "__main__":
    main()
